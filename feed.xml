<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <title>Digitial Library of Integral Ecology Knowledge Graph</title>
  <subtitle>Tutorials for building open tools for ecological understanding</subtitle>
  <link href="https://clirdlf.github.io/dlie_knowledge_graph/feed.xml" rel="self" />
  <link href="https://clirdlf.github.io/dlie_knowledge_graph/" />
  <updated>2025-06-09T00:00:00Z</updated>
  <id>https://clirdlf.github.io/dlie_knowledge_graph/</id>
  <author>
    <name>Council on Library and Information Resources</name>
  </author>
  <entry>
    <title>Contribute: Join the Digital Library of Integral Ecology</title>
    <link href="https://clirdlf.github.io/dlie_knowledge_graph/posts/contribute-join-the-digital-library-of-integral-ecology/" />
    <updated>2025-06-09T00:00:00Z</updated>
    <id>https://clirdlf.github.io/dlie_knowledge_graph/posts/contribute-join-the-digital-library-of-integral-ecology/</id>
    <content type="html">&lt;p&gt;This project is not just about building technology ‚Äî it‚Äôs about building &lt;strong&gt;community&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;The Digital Library of Integral Ecology is a shared, open infrastructure for people who care about the Earth, its people, and our common future. It brings together knowledge from science, policy, spirituality, and grassroots voices ‚Äî and we want you to be part of it.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;ways-to-get-involved&quot;&gt;Ways to Get Involved&lt;/h2&gt;&lt;p&gt;You don‚Äôt need to be a coder or a data scientist to contribute. Here are some ways anyone can help:&lt;/p&gt;&lt;h3 id=&quot;annotate-reports&quot;&gt;Annotate Reports&lt;/h3&gt;&lt;p&gt;Help tag ecological concepts, organizations, places, and ideas in documents using &lt;a href=&quot;https://github.com/doccano/doccano&quot;&gt;Doccano&lt;/a&gt;. No technical skill required ‚Äî just your careful reading.&lt;/p&gt;&lt;h3 id=&quot;share-reports-and-sources&quot;&gt;Share Reports and Sources&lt;/h3&gt;&lt;p&gt;We‚Äôre always looking for ecological reports in &lt;strong&gt;different languages&lt;/strong&gt; and from &lt;strong&gt;diverse contexts&lt;/strong&gt; (NGOs, indigenous communities, policy, faith-based orgs, etc.).&lt;/p&gt;&lt;p&gt;Send us PDFs or links to reports that should be included in the graph.&lt;/p&gt;&lt;h3 id=&quot;train-the-ai&quot;&gt;Train the AI&lt;/h3&gt;&lt;p&gt;If you&#39;re technical, help us fine-tune our ecological NER models using annotated data. Or contribute to multilingual tagging tools and model evaluation.&lt;/p&gt;&lt;h3 id=&quot;translate-and-extend&quot;&gt;Translate and Extend&lt;/h3&gt;&lt;p&gt;Want to add new languages? New entity types like &lt;strong&gt;species&lt;/strong&gt;, &lt;strong&gt;spiritual practices&lt;/strong&gt;, or &lt;strong&gt;sacred sites&lt;/strong&gt;? We&#39;re building a framework that‚Äôs meant to grow with your contributions.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;technical-contributors&quot;&gt;Technical Contributors&lt;/h2&gt;&lt;p&gt;If you‚Äôre a developer, here‚Äôs where you can help:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Improve entity extraction and citation linking&lt;/li&gt;&lt;li&gt;Enhance multilingual NLP support&lt;/li&gt;&lt;li&gt;Automate ingestion from online archives&lt;/li&gt;&lt;li&gt;Build interactive search and visualization tools&lt;/li&gt;&lt;li&gt;Create public datasets from the graph (JSONL, CSV, RDF, etc.)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Our &lt;a href=&quot;https://github.com/clirdlf/dlie_knowledge_graph&quot;&gt;GitHub repository&lt;/a&gt; includes Docker-based workflows, NLP scripts, a Makefile, and blog documentation ‚Äî all ready to clone and explore.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;how-to-get-started&quot;&gt;How to Get Started&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Star or fork the project on GitHub: &lt;a href=&quot;https://github.com/clirdlf/dlie_knowledge_graph&quot;&gt;github.com/clirdlf/dlie_knowledge_graph&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Clone the repo:&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;   &lt;span class=&quot;token function&quot;&gt;git&lt;/span&gt; clone https://github.com/clirdlf/dlie_knowledge_graph.git
   &lt;span class=&quot;token builtin class-name&quot;&gt;cd&lt;/span&gt; dlie_knowledge_graph
   &lt;span class=&quot;token function&quot;&gt;make&lt;/span&gt; up&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;Try annotating or improving a model:&lt;/li&gt;&lt;/ol&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;make&lt;/span&gt; pipeline &lt;span class=&quot;token assign-left variable&quot;&gt;PDF&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;my-report.pdf&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&quot;4&quot;&gt;&lt;li&gt;Join us on discussions (coming soon)&lt;/li&gt;&lt;/ol&gt;&lt;hr&gt;&lt;h2 id=&quot;we-re-building-this-together&quot;&gt;We‚Äôre Building This Together&lt;/h2&gt;&lt;p&gt;This project is inspired by the principles of &lt;strong&gt;integral ecology&lt;/strong&gt;, the idea that we must care for both the environment and the most vulnerable people it supports.&lt;/p&gt;&lt;p&gt;Building the Digital Library is a concrete act of hope. It‚Äôs a way to turn scattered, siloed knowledge into living, shared understanding.&lt;/p&gt;&lt;p&gt;Whether you‚Äôre a researcher, developer, librarian, artist, or student ‚Äî you are welcome.&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt;&lt;p&gt;‚ÄúAll it takes is one good person to restore hope.‚Äù ‚Äî Pope Francis, Laudato Si‚Äô&lt;/p&gt;&lt;/blockquote&gt;</content>
  </entry>
  <entry>
    <title>Evaluating the Results: Accuracy, Speed, and Insight</title>
    <link href="https://clirdlf.github.io/dlie_knowledge_graph/posts/evaluating-the-results-accuracy-speed-and-insight/" />
    <updated>2025-06-08T00:00:00Z</updated>
    <id>https://clirdlf.github.io/dlie_knowledge_graph/posts/evaluating-the-results-accuracy-speed-and-insight/</id>
    <content type="html">&lt;p&gt;We‚Äôve come a long way ‚Äî from PDFs to graphs, from automatic tagging to human annotation, and finally to training our own ecological NLP model.&lt;/p&gt;&lt;p&gt;But how do we know if it‚Äôs working?&lt;/p&gt;&lt;p&gt;In this post, we‚Äôll explore how to evaluate your pipeline and model using both &lt;strong&gt;standard NLP metrics&lt;/strong&gt; and &lt;strong&gt;real-world ecological insight&lt;/strong&gt;.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;why-evaluate&quot;&gt;Why Evaluate?&lt;/h2&gt;&lt;p&gt;Evaluation helps us understand:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;‚úÖ Is the model tagging entities accurately?&lt;/li&gt;&lt;li&gt;‚úÖ Does it work well across languages?&lt;/li&gt;&lt;li&gt;‚úÖ Is it fast enough for real-world use?&lt;/li&gt;&lt;li&gt;‚úÖ What kinds of mistakes does it make?&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Evaluation isn‚Äôt just about numbers ‚Äî it‚Äôs about improving &lt;strong&gt;trust&lt;/strong&gt;, &lt;strong&gt;transparency&lt;/strong&gt;, and &lt;strong&gt;impact&lt;/strong&gt;.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;key-metrics&quot;&gt;Key Metrics&lt;/h2&gt;&lt;h3 id=&quot;precision&quot;&gt;Precision&lt;/h3&gt;&lt;p&gt;The % of predicted entities that were correct&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Did it predict something meaningful?&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 id=&quot;recall&quot;&gt;Recall&lt;/h3&gt;&lt;p&gt;The % of correct entities that were successfully predicted&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Did it miss important things?&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 id=&quot;f1-score&quot;&gt;F1 Score&lt;/h3&gt;&lt;p&gt;The balance of precision and recall&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;A good all-around indicator&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;These metrics are calculated by comparing your model&#39;s output to &lt;strong&gt;human-annotated data&lt;/strong&gt;, usually exported from Doccano.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;how-to-evaluate-with-spacy&quot;&gt;How to Evaluate with spaCy&lt;/h2&gt;&lt;p&gt;After training, spaCy automatically evaluates on your dev/test set and shows:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;‚úî Accuracy: &lt;span class=&quot;token number&quot;&gt;89.2&lt;/span&gt;%
‚úî Precision: &lt;span class=&quot;token number&quot;&gt;88.5&lt;/span&gt;%
‚úî Recall: &lt;span class=&quot;token number&quot;&gt;90.1&lt;/span&gt;%
‚úî F1 Score: &lt;span class=&quot;token number&quot;&gt;89.3&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can also evaluate manually using:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;python &lt;span class=&quot;token parameter variable&quot;&gt;-m&lt;/span&gt; spacy evaluate ./output/model-best ./dev.spacy&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or export annotated JSONL and compare predictions programmatically.&lt;/p&gt;&lt;h2 id=&quot;speed-and-runtime&quot;&gt;Speed and Runtime&lt;/h2&gt;&lt;p&gt;You can also evaluate &lt;strong&gt;how fast&lt;/strong&gt; your model runs:&lt;/p&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; spacy&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; time
nlp &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; spacy&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;load&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;output/model-best&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
text &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;The WWF is active in the Amazon on climate resilience.&quot;&lt;/span&gt;

start &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; time&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;time&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
doc &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; nlp&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;text&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;ent&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;text&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; ent&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;label_&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; ent &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; doc&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;ents&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;Time:&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;time&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;time&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt; start&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;seconds&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This helps you decide:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Which model is best for live pipelines vs. batch runs&lt;/li&gt;&lt;li&gt;When to use sm vs. &lt;code&gt;lg&lt;/code&gt; or &lt;code&gt;trf&lt;/code&gt; models&lt;/li&gt;&lt;/ul&gt;&lt;hr&gt;&lt;h2 id=&quot;beyond-accuracy-ecological-insight&quot;&gt;Beyond Accuracy: Ecological Insight&lt;/h2&gt;&lt;p&gt;Numbers matter, but so does &lt;strong&gt;usefulness&lt;/strong&gt;!&lt;/p&gt;&lt;p&gt;Ask:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Does the graph help us find new connections?&lt;/li&gt;&lt;li&gt;Are multilingual documents being fairly represented?&lt;/li&gt;&lt;li&gt;Does it highlight underrepresented organizations or regions?&lt;/li&gt;&lt;li&gt;Is it surfacing unexpected insights for researchers or communities?&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These qualitative measures can be just as valuable as F1 score.&lt;/p&gt;&lt;h2 id=&quot;try-it-yourself&quot;&gt;Try It Yourself&lt;/h2&gt;&lt;p&gt;After training, run:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;python &lt;span class=&quot;token parameter variable&quot;&gt;-m&lt;/span&gt; spacy evaluate output/model-best dev.spacy&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or test it interactively:&lt;/p&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; spacy
nlp &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; spacy&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;load&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;output/model-best&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
doc &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; nlp&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;UNEP published a report on ecosystem resilience in East Africa.&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;ent&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;text&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; ent&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;label_&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; ent &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; doc&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;ents&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then compare the results to the baseline model (&lt;code&gt;en_core_web_sm&lt;/code&gt;) or TaxoNERD.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;whats-next&quot;&gt;What&#39;s Next&lt;/h2&gt;&lt;p&gt;You‚Äôve now seen the full lifecycle:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Extract text and citations from reports&lt;/li&gt;&lt;li&gt;Tag entities across languages&lt;/li&gt;&lt;li&gt;Upload to a knowledge graph&lt;/li&gt;&lt;li&gt;Annotate and refine human feedback&lt;/li&gt;&lt;li&gt;Train and evaluate your own model&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;You‚Äôre ready to contribute ‚Äî or build your own ecological pipeline.&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>Training Our Own Ecological Language Model</title>
    <link href="https://clirdlf.github.io/dlie_knowledge_graph/posts/training-our-own-ecological-language-model/" />
    <updated>2025-06-07T00:00:00Z</updated>
    <id>https://clirdlf.github.io/dlie_knowledge_graph/posts/training-our-own-ecological-language-model/</id>
    <content type="html">&lt;h1 id=&quot;training-our-own-ecological-language-model&quot;&gt;Training Our Own Ecological Language Model&lt;/h1&gt;&lt;p&gt;We‚Äôve built a working NLP pipeline that tags organizations, locations, and ecological concepts from multilingual reports. We‚Äôve even used Doccano to correct and improve those tags.&lt;/p&gt;&lt;p&gt;Now it‚Äôs time to &lt;strong&gt;teach the system&lt;/strong&gt; to do better ‚Äî by training our own custom NER model using the annotated data.&lt;/p&gt;&lt;p&gt;This post explains how we take human-labeled examples and turn them into a smarter, more accurate &lt;strong&gt;ecological language model&lt;/strong&gt;.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;why-train-a-custom-model&quot;&gt;Why Train a Custom Model?&lt;/h2&gt;&lt;p&gt;spaCy‚Äôs built-in models are trained on general-purpose data. They work well, but they don‚Äôt understand:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Domain-specific terms like &lt;em&gt;‚Äúclimate resilience‚Äù&lt;/em&gt;, &lt;em&gt;‚Äúeco-spirituality‚Äù&lt;/em&gt;, or &lt;em&gt;‚Äúintegral development‚Äù&lt;/em&gt;&lt;/li&gt;&lt;li&gt;New languages or spelling variants&lt;/li&gt;&lt;li&gt;Cross-domain relationships common in integral ecology (science + ethics + economics)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Training your own model lets you:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Add new entity types (e.g. &lt;code&gt;ECO_CONCEPT&lt;/code&gt;)&lt;/li&gt;&lt;li&gt;Improve accuracy for your documents&lt;/li&gt;&lt;li&gt;Adapt the system to your language and context&lt;/li&gt;&lt;/ul&gt;&lt;hr&gt;&lt;h2 id=&quot;tools-we-use&quot;&gt;Tools We Use&lt;/h2&gt;&lt;p&gt;We use &lt;a href=&quot;https://spacy.io&quot;&gt;spaCy&lt;/a&gt;‚Äôs training framework. It supports:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Training from scratch or fine-tuning&lt;/li&gt;&lt;li&gt;Evaluation metrics (precision, recall, F1)&lt;/li&gt;&lt;li&gt;Easy use of exported Doccano data&lt;/li&gt;&lt;/ul&gt;&lt;hr&gt;&lt;h2 id=&quot;from-doccano-to-training-data&quot;&gt;From Doccano to Training Data&lt;/h2&gt;&lt;p&gt;After annotating in Doccano:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Export your project as &lt;code&gt;.jsonl&lt;/code&gt;&lt;/li&gt;&lt;li&gt;Use a converter to turn that into spaCy format:&lt;/li&gt;&lt;/ol&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;spacy convert yourfile.jsonl ./train_data &lt;span class=&quot;token parameter variable&quot;&gt;--lang&lt;/span&gt; en &lt;span class=&quot;token parameter variable&quot;&gt;--ner&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This gives you &lt;code&gt;.spacy&lt;/code&gt; binary files for training.&lt;/p&gt;&lt;p&gt;Or use a Python script to convert to &lt;code&gt;train.json&lt;/code&gt;, &lt;code&gt;dev.json&lt;/code&gt; split manually.&lt;/p&gt;&lt;p&gt;‚∏ª&lt;/p&gt;&lt;h2 id=&quot;training-the-model&quot;&gt;Training the Model&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;Create a config file:&lt;/li&gt;&lt;/ol&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;python &lt;span class=&quot;token parameter variable&quot;&gt;-m&lt;/span&gt; spacy init config ./config.cfg &lt;span class=&quot;token parameter variable&quot;&gt;--lang&lt;/span&gt; en &lt;span class=&quot;token parameter variable&quot;&gt;--pipeline&lt;/span&gt; ner&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;Edit &lt;code&gt;config.cfg&lt;/code&gt;to match your needs (entity labels, GPU, batch size, etc.)&lt;/li&gt;&lt;li&gt;Prepare training assets:&lt;/li&gt;&lt;/ol&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;python &lt;span class=&quot;token parameter variable&quot;&gt;-m&lt;/span&gt; spacy init fill-config config.cfg config_final.cfg&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&quot;4&quot;&gt;&lt;li&gt;Train the model:&lt;/li&gt;&lt;/ol&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;python &lt;span class=&quot;token parameter variable&quot;&gt;-m&lt;/span&gt; spacy train config_final.cfg &lt;span class=&quot;token parameter variable&quot;&gt;--output&lt;/span&gt; ./output &lt;span class=&quot;token parameter variable&quot;&gt;--paths.train&lt;/span&gt; ./train.spacy &lt;span class=&quot;token parameter variable&quot;&gt;--paths.dev&lt;/span&gt; ./dev.spacy&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When done, your trained model will be in:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;./output/model-best&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can load it like this:&lt;/p&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; spacy
nlp &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; spacy&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;load&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;output/model-best&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;measuring-progress&quot;&gt;Measuring Progress&lt;/h2&gt;&lt;p&gt;During training, spaCy tracks:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Precision&lt;/strong&gt; ‚Äî how many predicted entities were correct&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Recall&lt;/strong&gt; ‚Äî how many true entities it found&lt;/li&gt;&lt;li&gt;&lt;strong&gt;F1 Score&lt;/strong&gt; ‚Äî a balance of the two&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This helps you compare:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Pre-trained model (baseline)&lt;/li&gt;&lt;li&gt;Your fine-tuned model (specialized)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;‚∏ª&lt;/p&gt;&lt;h2 id=&quot;try-it-yourself&quot;&gt;Try It Yourself&lt;/h2&gt;&lt;p&gt;Once you have annotations from Doccano:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;make&lt;/span&gt; train-model&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or step through each stage with:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;python &lt;span class=&quot;token parameter variable&quot;&gt;-m&lt;/span&gt; spacy init config ./config.cfg &lt;span class=&quot;token parameter variable&quot;&gt;--lang&lt;/span&gt; en &lt;span class=&quot;token parameter variable&quot;&gt;--pipeline&lt;/span&gt; ner
python &lt;span class=&quot;token parameter variable&quot;&gt;-m&lt;/span&gt; spacy train config.cfg &lt;span class=&quot;token parameter variable&quot;&gt;--output&lt;/span&gt; ./output &lt;span class=&quot;token parameter variable&quot;&gt;--paths.train&lt;/span&gt; ./train.spacy &lt;span class=&quot;token parameter variable&quot;&gt;--paths.dev&lt;/span&gt; ./dev.spacy&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Test the result:&lt;/p&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;nlp &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; spacy&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;load&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;output/model-best&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
doc &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; nlp&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;WWF works on climate resilience in the Amazon rainforest.&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;ent&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;text&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; ent&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;label_&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; ent &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; doc&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;ents&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&lt;h2 id=&quot;a-living-model&quot;&gt;A Living Model&lt;/h2&gt;&lt;p&gt;As more reports are added and more annotations made, we can:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Retrain the model periodically&lt;/li&gt;&lt;li&gt;Add multilingual support (e.g. &lt;code&gt;fr&lt;/code&gt;, &lt;code&gt;es&lt;/code&gt;, &lt;code&gt;zh&lt;/code&gt;)&lt;/li&gt;&lt;li&gt;Extend to more entity types (like &lt;code&gt;SPECIES&lt;/code&gt;, &lt;code&gt;DOCUMENT&lt;/code&gt;, &lt;code&gt;THEOLOGICAL_TERM&lt;/code&gt;)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This is how the Digital Library of Integral Ecology gets smarter over time ‚Äî powered by human insight and collaborative learning.&lt;/p&gt;&lt;p&gt;‚∏ª&lt;/p&gt;&lt;h2 id=&quot;what-s-next&quot;&gt;What‚Äôs Next?&lt;/h2&gt;&lt;p&gt;In the final post, we‚Äôll evaluate the full system and compare how well the pipeline performs &lt;strong&gt;before and after training&lt;/strong&gt;, across languages and document types.&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>Annotation: Teaching the System to Be Smarter</title>
    <link href="https://clirdlf.github.io/dlie_knowledge_graph/posts/annotation-teaching-the-system-to-be-smarter/" />
    <updated>2025-06-06T00:00:00Z</updated>
    <id>https://clirdlf.github.io/dlie_knowledge_graph/posts/annotation-teaching-the-system-to-be-smarter/</id>
    <content type="html">&lt;p&gt;Our pipeline can already extract text from reports, tag entities, and build a multilingual knowledge graph ‚Äî but how accurate is it?&lt;/p&gt;&lt;p&gt;The truth is: even good AI needs &lt;strong&gt;human correction&lt;/strong&gt;. That&#39;s where &lt;strong&gt;annotation&lt;/strong&gt; comes in.&lt;/p&gt;&lt;p&gt;In this post, we‚Äôll show you how we use &lt;strong&gt;Doccano&lt;/strong&gt;, a friendly web interface, to correct the output of our pipeline and help the model improve over time.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;why-annotation-matters&quot;&gt;Why Annotation Matters&lt;/h2&gt;&lt;p&gt;Even the best models make mistakes:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Misclassifying entities (e.g. &amp;quot;Amazon&amp;quot; as a product instead of a forest)&lt;/li&gt;&lt;li&gt;Missing subtle ecological terms (like ‚Äúresilience‚Äù or ‚Äúeco-conversion‚Äù)&lt;/li&gt;&lt;li&gt;Struggling with languages like Arabic or complex phrases&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Annotation lets humans:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Correct the labels&lt;/li&gt;&lt;li&gt;Add missing terms&lt;/li&gt;&lt;li&gt;Build reliable training data&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;It‚Äôs like proofreading ‚Äî but for a machine learning system.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;what-is-doccano&quot;&gt;What is Doccano?&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://doccano.github.io/doccano/&quot;&gt;Doccano&lt;/a&gt; is an open-source tool for &lt;strong&gt;annotating text for NLP tasks&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;It provides:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A browser-based interface&lt;/li&gt;&lt;li&gt;Support for named entity recognition (NER), classification, translation, and more&lt;/li&gt;&lt;li&gt;Role-based user access&lt;/li&gt;&lt;li&gt;Easy data import and export&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We use Doccano to refine the results of &lt;code&gt;ner_pipeline.py&lt;/code&gt;.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;exporting-to-doccano-format&quot;&gt;Exporting to Doccano Format&lt;/h2&gt;&lt;p&gt;After entity tagging, we export the results in &lt;a href=&quot;https://github.com/doccano/doccano/blob/master/docs/api.md#annotation-format&quot;&gt;JSONL format&lt;/a&gt;:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;python export_doccano.py my-report.entities.json&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Which creates:&lt;/p&gt;&lt;pre class=&quot;language-json&quot;&gt;&lt;code class=&quot;language-json&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;token property&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;The WWF report on the Amazon rainforest...&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;token property&quot;&gt;&quot;labels&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;ORG&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;36&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;LOC&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This format can be imported directly into Doccano.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;using-doccano-locally&quot;&gt;Using Doccano Locally&lt;/h2&gt;&lt;p&gt;If you‚Äôre running the project with Docker Compose, Doccano is already available at:&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://localhost:8000&quot;&gt;http://localhost:8000&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Log in with&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Username:&lt;/strong&gt; &lt;code&gt;admin&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Password:&lt;/strong&gt; &lt;code&gt;password&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;From there, you can&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Create a new NER project&lt;/li&gt;&lt;li&gt;Import your &lt;code&gt;.jsonl&lt;/code&gt; file (generated in previous step)&lt;/li&gt;&lt;li&gt;Start tagging!&lt;/li&gt;&lt;/ol&gt;&lt;hr&gt;&lt;h2 id=&quot;the-feedback-loop&quot;&gt;The Feedback Loop&lt;/h2&gt;&lt;p&gt;Once documents are annotated in Doccano, we:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Export the clean annotations&lt;/li&gt;&lt;li&gt;Convert them to spaCy training format&lt;/li&gt;&lt;li&gt;Fine-tune a custom NER model&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;This cycle helps the system:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Improve tagging accuracy&lt;/li&gt;&lt;li&gt;Recognize new or uncommon terms&lt;/li&gt;&lt;li&gt;Adapt to multilingual and ecological contexts&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We call this process &lt;strong&gt;active learning&lt;/strong&gt;.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;try-it-yourself&quot;&gt;Try It Yourself&lt;/h2&gt;&lt;p&gt;If you‚Äôve already run:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;make&lt;/span&gt; pipeline &lt;span class=&quot;token assign-left variable&quot;&gt;PDF&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;my-report.pdf&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then a Doccano file will be created at:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;data/doccano/my-report.entities.jsonl&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Import this file into your Doccano project and try refining the labels!&lt;/p&gt;&lt;h2 id=&quot;who-can-help&quot;&gt;Who Can Help?&lt;/h2&gt;&lt;p&gt;Annotation is one of the best ways to contribute, especially if you:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Are a researcher in ecology, theology, or social sciences&lt;/li&gt;&lt;li&gt;Are bilingual or multilingual&lt;/li&gt;&lt;li&gt;Want to help shape AI to better understand the world&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;All you need is careful attention. &lt;strong&gt;No coding required!&lt;/strong&gt;&lt;/p&gt;&lt;h2 id=&quot;what-s-next&quot;&gt;What‚Äôs Next?&lt;/h2&gt;&lt;p&gt;Now that we have clean, annotated data, we‚Äôre ready to train our own &lt;strong&gt;ecologically informed NER model&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;In the next post, we‚Äôll walk through how to train a custom spaCy pipeline using your Doccano data.&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>Stitching the Graph: Saving Knowledge to Neo4j</title>
    <link href="https://clirdlf.github.io/dlie_knowledge_graph/posts/stitching-the-graph-saving-knowledge-to-neo4j/" />
    <updated>2025-06-05T00:00:00Z</updated>
    <id>https://clirdlf.github.io/dlie_knowledge_graph/posts/stitching-the-graph-saving-knowledge-to-neo4j/</id>
    <content type="html">&lt;p&gt;So far, we‚Äôve extracted clean text from ecological reports and used AI to identify important entities like organizations, places, and ecological concepts.&lt;/p&gt;&lt;p&gt;But identifying entities is only half the story. Now we need to &lt;strong&gt;connect&lt;/strong&gt; them ‚Äî to build our &lt;strong&gt;knowledge graph&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;In this post, we show how we use &lt;strong&gt;Neo4j&lt;/strong&gt;, a graph database, to stitch everything together into a network of knowledge.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;what-is-a-graph-database&quot;&gt;What is a Graph Database?&lt;/h2&gt;&lt;p&gt;A &lt;strong&gt;graph database&lt;/strong&gt; stores information as &lt;strong&gt;nodes&lt;/strong&gt; (things) and &lt;strong&gt;relationships&lt;/strong&gt; (connections).&lt;/p&gt;&lt;p&gt;Unlike traditional databases, which store rows and columns, a graph lets you explore:&lt;/p&gt;&lt;pre class=&quot;language-plaintext&quot;&gt;&lt;code class=&quot;language-plaintext&quot;&gt;(WWF Report) ‚ÄìMENTIONS‚Äì&gt; (Amazon rainforest)
‚ÄìCITES‚Äî‚Äì&gt; (IPBES 2019 Report)
‚ÄìMENTIONS‚Äì&gt; (climate resilience)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Neo4j is the most popular open-source graph database. It‚Äôs:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Visual&lt;/li&gt;&lt;li&gt;Easy to query (using a language called Cypher)&lt;/li&gt;&lt;li&gt;Designed to handle relationships efficiently&lt;/li&gt;&lt;/ul&gt;&lt;hr&gt;&lt;h2 id=&quot;what-we-store-in-the-graph&quot;&gt;üß± What We Store in the Graph&lt;/h2&gt;&lt;p&gt;Each document and entity we extract becomes a &lt;strong&gt;node&lt;/strong&gt;, and their connections are modeled as &lt;strong&gt;relationships&lt;/strong&gt;.&lt;/p&gt;&lt;h3 id=&quot;node-types&quot;&gt;Node Types&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;:Document&lt;/code&gt; ‚Äî the report itself&lt;/li&gt;&lt;li&gt;&lt;code&gt;:Entity&lt;/code&gt; ‚Äî an extracted item (e.g. ‚ÄúWWF‚Äù, ‚ÄúAmazon rainforest‚Äù)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Each node has properties like:&lt;/p&gt;&lt;pre class=&quot;language-cypher&quot;&gt;&lt;code class=&quot;language-cypher&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Document&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;name&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;wwf_amazon_report&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; lang&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;en&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Entity&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;text&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;climate resilience&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; label&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;ECO_CONCEPT&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;relationship-types&quot;&gt;Relationship Types&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;(:Document)-[:MENTIONS]-&amp;gt;(:Entity)&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;(:Document)-[:CITES]-&amp;gt;(:Document)&lt;/code&gt; (coming soon via citation parsing)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These relationships make the knowledge &lt;strong&gt;navigable&lt;/strong&gt;, not just searchable.&lt;/p&gt;&lt;h2 id=&quot;how-it-works-in-code&quot;&gt;How It Works in Code&lt;/h2&gt;&lt;p&gt;After entity tagging, we load the data into Neo4j using:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;python graph_upload.py my-report.entities.json&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This script:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Loads the entity JSON file&lt;/li&gt;&lt;li&gt;Creates the &lt;code&gt;:Document&lt;/code&gt; node&lt;/li&gt;&lt;li&gt;Creates one &lt;code&gt;:Entity&lt;/code&gt; node per unique mention&lt;/li&gt;&lt;li&gt;Connects them with &lt;code&gt;:MENTIONS&lt;/code&gt; relationships&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;You can view this graph in Neo4j‚Äôs browser:&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://localhost:7474&quot;&gt;http://localhost:7474&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Use the default login:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Username:&lt;/strong&gt; neo4j&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Password:&lt;/strong&gt; password&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;And run a query like:&lt;/p&gt;&lt;pre class=&quot;language-cypher&quot;&gt;&lt;code class=&quot;language-cypher&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;MATCH&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;d&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Document&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token relationship property&quot;&gt;MENTIONS&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;e&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Entity&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;RETURN&lt;/span&gt; d&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; e&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&lt;h2 id=&quot;try-it-yourself&quot;&gt;Try It Yourself&lt;/h2&gt;&lt;p&gt;If you‚Äôve run the full pipeline:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;make&lt;/span&gt; pipeline &lt;span class=&quot;token assign-left variable&quot;&gt;PDF&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;my-report.pdf&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The upload to Neo4j is done automatically. Otherwise, you can run it directly:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;docker&lt;/span&gt; compose &lt;span class=&quot;token builtin class-name&quot;&gt;exec&lt;/span&gt; worker python graph_upload.py my-report.entities.json&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then open Neo4j in your browser and start exploring the graph!&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;what-can-you-do-with-it&quot;&gt;What Can You Do With It?&lt;/h2&gt;&lt;p&gt;Once in the graph, you can:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Find all documents mentioning a specific concept&lt;/li&gt;&lt;li&gt;Discover what organizations work in similar regions&lt;/li&gt;&lt;li&gt;Visualize themes and citations across languages&lt;/li&gt;&lt;li&gt;Prepare data for annotation or deeper AI training&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This is where our static data becomes &lt;strong&gt;living knowledge&lt;/strong&gt;.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;what-s-next&quot;&gt;What‚Äôs Next?&lt;/h2&gt;&lt;p&gt;Now that our knowledge is structured and searchable, we‚Äôll look at how to &lt;strong&gt;export the data to Doccano&lt;/strong&gt;, a simple annotation tool that lets humans teach the system to improve over time.&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>Tagging the World: Finding Places, Plants, and Ideas with AI</title>
    <link href="https://clirdlf.github.io/dlie_knowledge_graph/posts/tagging-the-world-finding-places-plants-and-ideas-with-ai/" />
    <updated>2025-06-04T00:00:00Z</updated>
    <id>https://clirdlf.github.io/dlie_knowledge_graph/posts/tagging-the-world-finding-places-plants-and-ideas-with-ai/</id>
    <content type="html">&lt;p&gt;Once we&#39;ve extracted clean text from a PDF, the next step is to &lt;strong&gt;understand what‚Äôs being talked about&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;That‚Äôs where Natural Language Processing (NLP) comes in.&lt;/p&gt;&lt;p&gt;We use NLP to scan the text and find key pieces of information ‚Äî like:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Locations (e.g. &amp;quot;Amazon rainforest&amp;quot;)&lt;/li&gt;&lt;li&gt;Organizations (e.g. &amp;quot;WWF&amp;quot;)&lt;/li&gt;&lt;li&gt;Ecological concepts (e.g. &amp;quot;resilience&amp;quot;, &amp;quot;biodiversity loss&amp;quot;)&lt;/li&gt;&lt;li&gt;Citations (e.g. &amp;quot;IPBES 2019 Report&amp;quot;)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Each of these is called an &lt;strong&gt;entity&lt;/strong&gt;, and this process is called &lt;strong&gt;Named Entity Recognition (NER)&lt;/strong&gt;.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;what-is-named-entity-recognition&quot;&gt;What is Named Entity Recognition?&lt;/h2&gt;&lt;p&gt;NER is a type of AI model that reads text and labels the parts that represent real-world things.&lt;/p&gt;&lt;p&gt;Example:&lt;/p&gt;&lt;pre class=&quot;language-plaintext&quot;&gt;&lt;code class=&quot;language-plaintext&quot;&gt;Original text:
The WWF report on the Amazon rainforest highlights climate resilience strategies.

NER output:
[ORG: WWF], [LOC: Amazon rainforest], [ECO_CONCEPT: climate resilience]&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This gives us structured data from unstructured sentences, and helps us populate our knowledge graph with &lt;strong&gt;nodes and connections&lt;/strong&gt;.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;tools-we-use&quot;&gt;Tools We Use&lt;/h2&gt;&lt;h3 id=&quot;spacy&quot;&gt;spaCy&lt;/h3&gt;&lt;p&gt;We use &lt;a href=&quot;https://spacy.io&quot;&gt;spaCy&lt;/a&gt;, a popular open-source NLP library that can:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Work in English, Spanish, French, Chinese, Russian, and more&lt;/li&gt;&lt;li&gt;Recognize standard entities like ORG, LOC, PERSON, etc.&lt;/li&gt;&lt;li&gt;Run fast and integrate easily with Python&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;taxonerd&quot;&gt;TaxoNERD&lt;/h3&gt;&lt;p&gt;For ecological texts, general NLP isn‚Äôt enough ‚Äî so we also use &lt;a href=&quot;https://github.com/nleguillarme/taxonerd&quot;&gt;TaxoNERD&lt;/a&gt;, a tool trained to detect ecological and taxonomic entities, like:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Ecosystem types&lt;/li&gt;&lt;li&gt;Species groups&lt;/li&gt;&lt;li&gt;Environmental terms&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/nleguillarme/taxonerd&quot;&gt;TaxoNERD&lt;/a&gt; uses a model called &lt;a href=&quot;https://github.com/dmis-lab/biobert&quot;&gt;BioBERT&lt;/a&gt; and is specialized for ecological language.&lt;/p&gt;&lt;h3 id=&quot;multilingual-support&quot;&gt;Multilingual Support&lt;/h3&gt;&lt;p&gt;We also include spaCy models for:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://spacy.io/models/fr#fr_core_news_lg&quot;&gt;fr_core_news_lg&lt;/a&gt; (French)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://spacy.io/models/es#es_core_news_lg&quot;&gt;es_core_news_lg&lt;/a&gt; (Spanish)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://spacy.io/models/zh#zh_core_web_trf&quot;&gt;zh_core_web_trf&lt;/a&gt; (Chinese)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://spacy.io/models/xx#xx_ent_wiki_sm&quot;&gt;xx_ent_wiki_sm&lt;/a&gt; (basic multilingual)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This makes the system &lt;strong&gt;language-aware&lt;/strong&gt;, even when documents span continents.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;how-it-works-in-code&quot;&gt;How It Works in Code&lt;/h2&gt;&lt;p&gt;The tagging is handled by this command:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;python ner_pipeline.py my-report.txt&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Which produces:&lt;/p&gt;&lt;pre class=&quot;language-json&quot;&gt;&lt;code class=&quot;language-json&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;token property&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;...&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;token property&quot;&gt;&quot;entities&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token property&quot;&gt;&quot;start&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token property&quot;&gt;&quot;end&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;22&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token property&quot;&gt;&quot;label&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;LOC&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token property&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;Amazon rainforest&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token property&quot;&gt;&quot;start&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;31&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token property&quot;&gt;&quot;end&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;34&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token property&quot;&gt;&quot;label&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;ORG&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token property&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;WWF&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token property&quot;&gt;&quot;start&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;45&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token property&quot;&gt;&quot;end&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;63&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token property&quot;&gt;&quot;label&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;ECO_CONCEPT&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token property&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;climate resilience&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is saved as &lt;code&gt;my-report.entities.json&lt;/code&gt; in the &lt;code&gt;data/output/&lt;/code&gt; directory.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;why-this-matters&quot;&gt;Why This Matters&lt;/h2&gt;&lt;p&gt;Recognizing entities allows us to:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Link a sentence to the right concepts&lt;/li&gt;&lt;li&gt;Group reports by theme or region&lt;/li&gt;&lt;li&gt;Connect related documents, even across languages&lt;/li&gt;&lt;li&gt;Support annotation and model training&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;It‚Äôs the first step toward turning plain text into a semantic map.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;try-it-yourself&quot;&gt;Try It Yourself&lt;/h2&gt;&lt;p&gt;If you‚Äôve already extracted text using:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;make&lt;/span&gt; pipeline &lt;span class=&quot;token assign-left variable&quot;&gt;PDF&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;/data/input/sample1.pdf&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The entity tagging will run automatically. Check the output in:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;data/output/sample1.entities.json&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can also run it independently:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;docker&lt;/span&gt; compose &lt;span class=&quot;token builtin class-name&quot;&gt;exec&lt;/span&gt; worker python ner_pipeline.py /data/input/sample1.txt&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&lt;h2 id=&quot;what-s-next&quot;&gt;What‚Äôs Next?&lt;/h2&gt;&lt;p&gt;Next, we‚Äôll take these entities and load them into Neo4j ‚Äî our graph database ‚Äî where we can start to visualize and query relationships.&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>From PDF to Text: Extracting Meaning from Documents</title>
    <link href="https://clirdlf.github.io/dlie_knowledge_graph/posts/from-pdf-to-text-extracting-meaning-from-documents/" />
    <updated>2025-06-03T00:00:00Z</updated>
    <id>https://clirdlf.github.io/dlie_knowledge_graph/posts/from-pdf-to-text-extracting-meaning-from-documents/</id>
    <content type="html">&lt;p&gt;The first step in building a knowledge graph for integral ecology is simple in concept ‚Äî but tricky in practice:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;How do we get clean, usable &lt;strong&gt;text&lt;/strong&gt; from messy, multilingual &lt;strong&gt;PDF reports&lt;/strong&gt;?&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;This post explains how we extract both the &lt;strong&gt;raw text&lt;/strong&gt; and the &lt;strong&gt;structured citations&lt;/strong&gt; from reports using two tools:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://pymupdf.readthedocs.io/en/latest/index.html&quot;&gt;PyMuPDF&lt;/a&gt; for text&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://grobid.readthedocs.io/en/latest/&quot;&gt;GROBID&lt;/a&gt; for citations and metadata&lt;/li&gt;&lt;/ul&gt;&lt;hr&gt;&lt;h2 id=&quot;why-this-matters&quot;&gt;Why This Matters&lt;/h2&gt;&lt;p&gt;PDFs are designed for printing, not for reading by machines.&lt;/p&gt;&lt;p&gt;They can include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Columns and footnotes&lt;/li&gt;&lt;li&gt;Images, tables, and scanned pages&lt;/li&gt;&lt;li&gt;Embedded fonts or malformed characters&lt;/li&gt;&lt;li&gt;Multiple languages in one document&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;If we want to detect entities and link knowledge later, we need high-quality &lt;strong&gt;plain text&lt;/strong&gt;.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;step-1-extract-text-with-pymupdf&quot;&gt;Step 1: Extract Text with PyMuPDF&lt;/h2&gt;&lt;p&gt;We use &lt;a href=&quot;https://pymupdf.readthedocs.io/&quot;&gt;&lt;code&gt;PyMuPDF&lt;/code&gt;&lt;/a&gt; (also known as &lt;code&gt;fitz&lt;/code&gt;) to extract the text page-by-page from a PDF.&lt;/p&gt;&lt;p&gt;It:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Preserves layout well&lt;/li&gt;&lt;li&gt;Handles multiple languages&lt;/li&gt;&lt;li&gt;Works with scanned+OCR‚Äôd documents if text is embedded&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Example output:&lt;/strong&gt;&lt;/p&gt;&lt;pre class=&quot;language-plaintext&quot;&gt;&lt;code class=&quot;language-plaintext&quot;&gt;The Amazon rainforest is shrinking rapidly.

WWF reported that deforestation increased 12% in 2023.&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This text gets saved as &lt;code&gt;report.txt&lt;/code&gt;.&lt;/p&gt;&lt;h2 id=&quot;step-2-extract-citations-with-grobid&quot;&gt;Step 2: Extract Citations with GROBID&lt;/h2&gt;&lt;p&gt;Next, we use &lt;a href=&quot;https://github.com/kermitt2/grobid&quot;&gt;GROBID&lt;/a&gt;, a tool that reads the bibliography and metadata of academic papers and reports.&lt;/p&gt;&lt;p&gt;GROBID converts messy citation lists like:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;[12] Smith, J., ‚ÄúBiodiversity and Forests‚Äù, Nature, 2020&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Into structured, machine-readable &lt;strong&gt;TEI XML&lt;/strong&gt;, which can include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Title&lt;/li&gt;&lt;li&gt;Authors&lt;/li&gt;&lt;li&gt;Year&lt;/li&gt;&lt;li&gt;Journal or publisher&lt;/li&gt;&lt;li&gt;DOI or identifiers&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We save this as &lt;code&gt;report.biblio.xml&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Later in the pipeline, this will help us:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Build &lt;strong&gt;:CITES relationships&lt;/strong&gt; in the graph&lt;/li&gt;&lt;li&gt;Match references across reports&lt;/li&gt;&lt;li&gt;Cluster similar reports by their sources&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;how-this-works-in-code&quot;&gt;How This Works in Code&lt;/h2&gt;&lt;p&gt;Our system includes a script that does this automatically:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;python extract_text.py my-report.pdf&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It will:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Extract the full text using PyMuPDF ‚Üí &lt;code&gt;my-report.txt&lt;/code&gt;&lt;/li&gt;&lt;li&gt;Send the PDF to the GROBID API ‚Üí &lt;code&gt;my-report.biblio.xml&lt;/code&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The script runs inside a Docker container and outputs files to the &lt;code&gt;/data/output/&lt;/code&gt; folder.&lt;/p&gt;&lt;h2 id=&quot;try-it-yourself&quot;&gt;Try It Yourself&lt;/h2&gt;&lt;p&gt;If you‚Äôve followed the setup from &lt;a href=&quot;https://clirdlf.github.io/dlie_knowledge_graph/posts/20_building_blocks/&quot;&gt;Part 2&lt;/a&gt;, you can run:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;make&lt;/span&gt; pipeline &lt;span class=&quot;token assign-left variable&quot;&gt;PDF&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;my-report.pdf&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Extract text and citations&lt;/li&gt;&lt;li&gt;Tag entities (coming up in Part 4)&lt;/li&gt;&lt;li&gt;Load data into Neo4j&lt;/li&gt;&lt;li&gt;Export annotated text for review&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Check the results in &lt;code&gt;data/output/&lt;/code&gt; ‚Äî you‚Äôll see &lt;code&gt;.txt&lt;/code&gt;, &lt;code&gt;.entities.json&lt;/code&gt;, and &lt;code&gt;.biblio.xml&lt;/code&gt; files.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;what-we-learned&quot;&gt;What We Learned&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;PDFs are tricky, but PyMuPDF gives us reliable plain text&lt;/li&gt;&lt;li&gt;GROBID gives us structured citations, ready for linking&lt;/li&gt;&lt;li&gt;Clean text is the foundation for everything that follows&lt;/li&gt;&lt;/ul&gt;&lt;hr&gt;&lt;h2 id=&quot;what-s-next&quot;&gt;What‚Äôs Next?&lt;/h2&gt;&lt;p&gt;In the next post, we‚Äôll explore how we tag entities in the text using AI ‚Äî recognizing organizations, locations, ecological concepts, and more.&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>Building Blocks: Documents, Entities, and Relationships</title>
    <link href="https://clirdlf.github.io/dlie_knowledge_graph/posts/building-blocks-documents-entities-and-relationships/" />
    <updated>2025-06-02T00:00:00Z</updated>
    <id>https://clirdlf.github.io/dlie_knowledge_graph/posts/building-blocks-documents-entities-and-relationships/</id>
    <content type="html">&lt;p&gt;In our last post, we introduced the vision: building a knowledge graph for &lt;strong&gt;integral ecology&lt;/strong&gt;, a way to connect people, places, organizations, and ideas across languages and disciplines.&lt;/p&gt;&lt;p&gt;But how exactly do we turn messy PDFs and complex reports into a meaningful, searchable web of knowledge?&lt;/p&gt;&lt;p&gt;We start with three key building blocks:&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;1-documents&quot;&gt;1. Documents&lt;/h2&gt;&lt;p&gt;The foundation of our knowledge graph is a &lt;strong&gt;document&lt;/strong&gt; ‚Äî a report, academic paper, policy brief, or even a faith-based reflection.&lt;/p&gt;&lt;p&gt;Each document is:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A single file (usually a PDF)&lt;/li&gt;&lt;li&gt;With a title, language, source (UNEP, WWF, OpenAlex, etc.)&lt;/li&gt;&lt;li&gt;That contains many sentences ‚Äî and lots of &lt;strong&gt;information hidden in plain text&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We treat each document as a &lt;strong&gt;node&lt;/strong&gt; in the graph, and from there, we extract meaning.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;2-entities&quot;&gt;2. Entities&lt;/h2&gt;&lt;p&gt;Entities are &lt;strong&gt;things that the document talks about&lt;/strong&gt; ‚Äî people, organizations, species, places, and ecological concepts.&lt;/p&gt;&lt;p&gt;For example:&lt;/p&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Entity Text&lt;/th&gt;&lt;th&gt;Label&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Amazon rainforest&lt;/td&gt;&lt;td&gt;&lt;code&gt;LOCATION&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;WWF&lt;/td&gt;&lt;td&gt;&lt;code&gt;ORG&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;climate resilience&lt;/td&gt;&lt;td&gt;&lt;code&gt;ECO_CONCEPT&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Laudato Si‚Äô&lt;/td&gt;&lt;td&gt;&lt;code&gt;DOCUMENT&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Our system uses &lt;strong&gt;Natural Language Processing (NLP)&lt;/strong&gt; tools to automatically recognize these entities in many languages ‚Äî with models trained on large text collections.&lt;/p&gt;&lt;p&gt;Later, we‚Äôll even &lt;strong&gt;fine-tune our own models&lt;/strong&gt; to be more accurate for ecological language.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;3-relationships&quot;&gt;3. Relationships&lt;/h2&gt;&lt;p&gt;The real power of a knowledge graph comes from the &lt;strong&gt;connections between entities&lt;/strong&gt; ‚Äî also called &lt;strong&gt;edges&lt;/strong&gt; or &lt;strong&gt;relationships&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;Some examples:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A document &lt;strong&gt;MENTIONS&lt;/strong&gt; an entity&lt;/li&gt;&lt;li&gt;A document &lt;strong&gt;CITES&lt;/strong&gt; another document&lt;/li&gt;&lt;li&gt;A concept &lt;strong&gt;IS_RELATED_TO&lt;/strong&gt; another concept&lt;/li&gt;&lt;li&gt;An organization &lt;strong&gt;WORKS_IN&lt;/strong&gt; a specific region&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These relationships turn isolated data points into an &lt;strong&gt;interconnected network&lt;/strong&gt; ‚Äî where you can explore patterns, paths, and shared meaning.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;putting-it-together&quot;&gt;Putting It Together&lt;/h2&gt;&lt;p&gt;Here&#39;s a simple example:&lt;/p&gt;&lt;pre class=&quot;language-cypher&quot;&gt;&lt;code class=&quot;language-cypher&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;WWF Report&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;‚ÄìMENTIONS‚Äì&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;Amazon rainforest&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
‚ÄìMENTIONS‚Äì&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;climate resilience&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
‚ÄìCITES‚Äî‚Äì&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;IPBES &lt;span class=&quot;token number&quot;&gt;2022&lt;/span&gt; Report&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In the graph database, each of these is a &lt;strong&gt;node&lt;/strong&gt; (document or entity) and each arrow is a &lt;strong&gt;relationship&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;We can now:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Search for all reports mentioning &amp;quot;climate resilience&amp;quot;&lt;/li&gt;&lt;li&gt;Find which NGOs cite a particular scientific assessment&lt;/li&gt;&lt;li&gt;Map ecological priorities across language and region&lt;/li&gt;&lt;/ul&gt;&lt;hr&gt;&lt;h2 id=&quot;why-it-matters&quot;&gt;Why It Matters&lt;/h2&gt;&lt;p&gt;This model gives us:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Structure&lt;/strong&gt; ‚Äî so we can search and analyze consistently&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt; ‚Äî works for hundreds or thousands of documents&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Interoperability&lt;/strong&gt; ‚Äî can be visualized, queried, and shared&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;And it sets the stage for automation, collaboration, and learning.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;try-it-yourself-clone-and-run-the-project&quot;&gt;Try It Yourself: Clone &amp;amp; Run the Project&lt;/h2&gt;&lt;p&gt;You can explore and run this pipeline locally using Docker.&lt;/p&gt;&lt;h3 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.docker.com/&quot;&gt;Docker&lt;/a&gt; (Desktop or CLI)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://git-scm.com/&quot;&gt;Git&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;step-1-clone-the-repository&quot;&gt;Step 1: Clone the Repository&lt;/h3&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;git&lt;/span&gt; clone https://github.com/clirdlf/dlie_knowledge_graph.git
&lt;span class=&quot;token builtin class-name&quot;&gt;cd&lt;/span&gt; dlie_knowledge_graph&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;step-2-build-and-start-the-system&quot;&gt;Step 2: Build and Start the System&lt;/h3&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;make&lt;/span&gt; build
&lt;span class=&quot;token function&quot;&gt;make&lt;/span&gt; up&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will spin up:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://grobid.readthedocs.io/en/latest/&quot;&gt;GROBID&lt;/a&gt; for citation parsing&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://neo4j.com/&quot;&gt;Neo4j&lt;/a&gt; for the knowledge graph&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://doccano.github.io/doccano/&quot;&gt;Doccano&lt;/a&gt; for annotation&lt;/li&gt;&lt;li&gt;A Python environment for text and entity extraction&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Then, you can run the full pipeline like this:&lt;/p&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;make&lt;/span&gt; pipeline &lt;span class=&quot;token assign-left variable&quot;&gt;PDF&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;/data/input/202206_IPBES_GLOBALREPORT.pdf&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You‚Äôll find the results in the &lt;code&gt;data/output/&lt;/code&gt; and &lt;code&gt;data/doccano/&lt;/code&gt; folders.&lt;/p&gt;&lt;h2 id=&quot;what-s-next&quot;&gt;What‚Äôs Next?&lt;/h2&gt;&lt;p&gt;In the next post, we‚Äôll start &lt;strong&gt;extracting text from real reports&lt;/strong&gt; ‚Äî even messy PDFs ‚Äî using smart tools like PyMuPDF and GROBID.&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>What is a Knowledge Graph for Integral Ecology?</title>
    <link href="https://clirdlf.github.io/dlie_knowledge_graph/posts/what-is-a-knowledge-graph-for-integral-ecology/" />
    <updated>2025-06-01T00:00:00Z</updated>
    <id>https://clirdlf.github.io/dlie_knowledge_graph/posts/what-is-a-knowledge-graph-for-integral-ecology/</id>
    <content type="html">&lt;p&gt;We live in an age of overwhelming information, but ecological knowledge, wisdom, and action often remain &lt;strong&gt;fragmented&lt;/strong&gt;, buried in reports, scattered across languages, or locked in formats only specialists can access.&lt;/p&gt;&lt;p&gt;That‚Äôs where the &lt;strong&gt;Digital Library of Integral Ecology&lt;/strong&gt; comes in. Our mission is to bring this information together, from scientific papers to NGO reports to faith-based reflections, into a single, interconnected digital library that helps researchers, educators, and communities act for the common good. One of the tools that helps us discovery and interrogate integral ecology is a knowledge graph. This codebase and set of tutorials will walk you through the technologies, opportunities, and tradeoffs in building this feature of the Digitial Library of Integral Ecology.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;what-do-we-mean-by-integral-ecology&quot;&gt;What Do We Mean by &amp;quot;Integral Ecology&amp;quot;?&lt;/h2&gt;&lt;p&gt;The term &lt;em&gt;integral ecology&lt;/em&gt; comes from &lt;em&gt;&lt;a href=&quot;https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html&quot;&gt;Laudato Si‚Äô&lt;/a&gt;&lt;/em&gt;, Pope Francis&#39; encyclical on the environment. It‚Äôs about recognizing the &lt;strong&gt;deep connections between ecological, social, cultural, and spiritual concerns&lt;/strong&gt;. Climate change, deforestation, loss of biodiversity ‚Äî these aren‚Äôt just technical problems. They are moral ones, economic ones, and spiritual ones too.&lt;/p&gt;&lt;p&gt;Integral ecology asks us to &lt;strong&gt;think in systems&lt;/strong&gt;, and to see how everything is connected.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;and-what-s-a-knowledge-graph&quot;&gt;And What‚Äôs a Knowledge Graph?&lt;/h2&gt;&lt;p&gt;A &lt;strong&gt;knowledge graph&lt;/strong&gt; is a way of storing and exploring knowledge by looking at &lt;strong&gt;relationships&lt;/strong&gt;. Imagine a big web:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A report mentions &lt;strong&gt;‚ÄúAmazon rainforest‚Äù&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;It connects to a &lt;strong&gt;location&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;The report is published by &lt;strong&gt;UNESCO&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;It discusses concepts like &lt;strong&gt;resilience&lt;/strong&gt; and &lt;strong&gt;biodiversity&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;It cites other documents that are connected too&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;All of this is represented not just as flat text, but as &lt;strong&gt;linked data&lt;/strong&gt; ‚Äî relationships between concepts, people, places, and ideas. This is what lets us ask better questions and see deeper patterns.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;what-we-re-building&quot;&gt;What We&#39;re Building&lt;/h2&gt;&lt;p&gt;We are creating a system that:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Extracts text&lt;/strong&gt; from ecological reports and scientific papers (even in PDF format)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Identifies key concepts&lt;/strong&gt;, organizations, places, species, and ideas ‚Äî in multiple languages&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Links them together&lt;/strong&gt; in a searchable, visual graph (using Neo4j)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Lets people annotate&lt;/strong&gt; and refine that knowledge with simple tools&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Trains smarter AI models&lt;/strong&gt; over time that understand ecology more deeply&lt;/li&gt;&lt;/ol&gt;&lt;hr&gt;&lt;h2 id=&quot;why-it-matters&quot;&gt;Why It Matters&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;Researchers can discover connections across disciplines and languages&lt;/li&gt;&lt;li&gt;NGOs can map their work to broader systems and goals&lt;/li&gt;&lt;li&gt;Educators can explore real-world ecological examples interactively&lt;/li&gt;&lt;li&gt;Communities can build shared understanding of their bioregions&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We believe this is a project not just of technology ‚Äî but of &lt;strong&gt;ecological conversion&lt;/strong&gt;.&lt;/p&gt;&lt;hr&gt;&lt;h2 id=&quot;what-s-next&quot;&gt;What‚Äôs Next?&lt;/h2&gt;&lt;p&gt;In the next post, we‚Äôll walk through the building blocks of the graph: &lt;strong&gt;documents, entities, and relationships&lt;/strong&gt;, and how we transform text into structure.&lt;/p&gt;</content>
  </entry>
</feed>